{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7306918e",
   "metadata": {},
   "source": [
    "## Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from utils.variables import * \n",
    "import scipy.stats as stats \n",
    "from scipy.stats import pearsonr, f_oneway, ttest_ind, chi2_contingency\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a80f33",
   "metadata": {},
   "source": [
    "## Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85b391",
   "metadata": {},
   "source": [
    "We begin by loading the dataset and examining the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "df_raw = pd.read_csv('../data/student_performance.csv')\n",
    "\n",
    "# Display first few rows and summary statistics of numeric columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df_raw.head())  \n",
    "display(df_raw.describe()) \n",
    "\n",
    "# Print columns with null values and their counts\n",
    "null_counts = df_raw.isnull().sum()\n",
    "print(null_counts[null_counts > 0] if not null_counts[null_counts > 0].empty else 'Dataframe has no null values')\n",
    "print(f'columns: {len(df_raw.columns)}, rows: {len(df_raw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7573fe",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- There are 33 columns, including the target variable G3.\n",
    "- There are 649 observed students\n",
    "- Numeric columns show expected ranges and summary statistics.\n",
    "- There are no missing values, making preprocessing simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8b4b7",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dec47b",
   "metadata": {},
   "source": [
    "### Binary Encoding\n",
    "\n",
    "Binary categorical features (e.g., sex, schoolsup) are mapped to 0/1 for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------  Convert Binary Nominal Features to Binary Numeric -----------------\n",
    "\n",
    "# Define binary mappings\n",
    "binary_mappings = {\n",
    "    'school': {'GP': 1, 'MS': 0},\n",
    "    'sex': {'M': 1, 'F': 0},\n",
    "    'address': {'U': 1, 'R': 0},\n",
    "    'famsize': {'GT3': 1, 'LE3': 0},\n",
    "    'Pstatus': {'T': 1, 'A': 0},\n",
    "    'schoolsup': {'yes': 1, 'no': 0},\n",
    "    'famsup': {'yes': 1, 'no': 0},\n",
    "    'paid': {'yes': 1, 'no': 0},\n",
    "    'activities': {'yes': 1, 'no': 0},\n",
    "    'nursery': {'yes': 1, 'no': 0},\n",
    "    'higher': {'yes': 1, 'no': 0},\n",
    "    'internet': {'yes': 1, 'no': 0},\n",
    "    'romantic': {'yes': 1, 'no': 0}\n",
    "}\n",
    "\n",
    "# Make a copy of the raw dataframe\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Apply mappings column by column and ensure integer type\n",
    "for col, mapping in binary_mappings.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping).astype(int)\n",
    "\n",
    "# Save the preprocessed dataset\n",
    "df.to_csv('../data/student_preprocessed.csv', index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bee90",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Binary variables are converted for computation in models like OLS and tree-based algorithms.\n",
    "- Four multi-category nominal variables remain (dtype: object) and will be one-hot encoded later \n",
    "- Data set is clean and ready for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712c791",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved preprocessed dataset\n",
    "df = pd.read_csv('../data/student_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf41c2",
   "metadata": {},
   "source": [
    "### Distributions of Categorical Variables\n",
    "\n",
    "We visualize the count of students for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Count Plots for Categorical Variables -------------------\n",
    "\n",
    "# Function to create chart titles\n",
    "def make_title(var):\n",
    "    return f\"Counts by {var.replace('_', ' ').title()}\"\n",
    "\n",
    "# Plot setup\n",
    "n_vars = len(cat_vars)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_vars / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*4, n_rows*4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through categorical variables\n",
    "for i, col in enumerate(cat_vars):\n",
    "    sns.countplot(x=col, data=df_raw, hue=col, palette=\"pastel\", ax=axes[i])        # Use df_raw to show original categories\n",
    "    axes[i].set_title(make_title(col))\n",
    "    if axes[i].get_legend() is not None:\n",
    "        axes[i].get_legend().remove()\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../visualizations/categorical_counts.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc84f4",
   "metadata": {},
   "source": [
    "### Distributions of Continuous Variables\n",
    "\n",
    "We check distributions and skewness for continuous variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Distributions & Skewness of Continuous Variables ----------------\n",
    "\n",
    "# Set style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "\n",
    "# Plot distributions and boxplots for continuous variables\n",
    "fig, axes = plt.subplots(len(cont_vars), 2, figsize=(10, 15))\n",
    "for i, var in enumerate(cont_vars):\n",
    "    kde_flag = False if var == 'age' else True  # No KDE for age due to discrete nature\n",
    "\n",
    "    # Histogram with KDE\n",
    "    sns.histplot(df[var], kde=kde_flag, ax=axes[i, 0], color=\"skyblue\")\n",
    "    skewness = df[var].skew()\n",
    "    axes[i, 0].set_title(f\"Distribution of {var} (Skewness: {skewness:.2f})\")\n",
    "    \n",
    "    # Boxplot\n",
    "    sns.boxplot(x=df[var], ax=axes[i, 1], color=\"lightcoral\")\n",
    "    axes[i, 1].set_title(f\"Boxplot of {var}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../visualizations/continuous_distributions.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e2e81",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Most variables are approximately symmetric, except absences (right-skewed).\n",
    "- Boxplots reveal outliers in absences and some grades (G1, G2).\n",
    "- The target G3 is left-skewed, we will address this later\n",
    "\n",
    "**Interpretation**\n",
    "- Skewed variables may require transformations in some models.\n",
    "- Outliers can affect OLS estimates; we'll consider removing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b41866",
   "metadata": {},
   "source": [
    "### Numeric Relationships with G3\n",
    "\n",
    "Scatterplots with regression lines show linear associations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bf799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Scatter Plots & Regression vs G3 for Numeric Variables ------------------\n",
    "\n",
    "# Remove 'G3' to avoid plotting vs itself\n",
    "numeric_vars = [var for var in numeric_vars if var != 'G3']\n",
    "\n",
    "# Determine grid size\n",
    "n_vars = len(numeric_vars)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_vars / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*4, n_rows*4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through variables and plot scatter + regression vs G3\n",
    "for i, col in enumerate(numeric_vars):\n",
    "    # Calculate correlation coefficient\n",
    "    r = df[col].corr(df['G3'])\n",
    "    \n",
    "    sns.regplot(\n",
    "        x=col,\n",
    "        y='G3',\n",
    "        data=df,\n",
    "        scatter_kws={'alpha':0.5},\n",
    "        line_kws={'color':'red'},\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"G3 vs {col} (r = {r:.2f})\")\n",
    "\n",
    "# Remove any unused axes\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../visualizations/scatter_regression_g3.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab3faf",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- G1 and G2 show the strongest correlation with G3 (r ≈ 0.83 & 0.92).\n",
    "- Other variables like famrel show weak correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7913a",
   "metadata": {},
   "source": [
    "### Pairwise Comparision of Categorical Variables vs G3\n",
    "\n",
    "Boxplots and barplots summarize mean performance by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Group Comparisons (Boxplots & Bar charts) ----------------\n",
    "n_vars = len(bin_vars + ord_vars)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_vars / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*4, n_rows*4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(bin_vars + ord_vars):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Binary variables (boxplot)\n",
    "    if var in bin_vars:\n",
    "        sns.boxplot(x=var, y='G3', data=df_raw, ax=ax, palette='pastel', hue=var)\n",
    "        ax.set_title(f\"G3 by {var}\")\n",
    "    \n",
    "    # Ordinal variables (barplot of mean G3)\n",
    "    elif var in ord_vars:\n",
    "        sns.barplot(x=var, y='G3', data=df_raw, errorbar=None, ax=ax, palette='pastel', hue=var)\n",
    "        ax.set_title(f\"Mean G3 by {var}\")\n",
    "    \n",
    "    # Remove legend \n",
    "    legend = ax.get_legend()\n",
    "    if legend is not None:\n",
    "        legend.remove()\n",
    "\n",
    "# Remove unused axes\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"../visualizations/group_comparisons.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed067372",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf0412",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "\n",
    "We examine correlations among numeric predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Correlation Matrix for Predictors ----------------\n",
    "\n",
    "# Encode nominal categorical variables using one-hot encoding\n",
    "df_encoded = df.copy()\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=nom_vars, drop_first=True)\n",
    "\n",
    "# Convert any boolean columns to int\n",
    "bool_cols = df_encoded.select_dtypes(include='bool').columns\n",
    "df_encoded[bool_cols] = df_encoded[bool_cols].astype(int)\n",
    "\n",
    "# Drop target variable to get predictors only\n",
    "X = df_encoded.drop(columns='G3')  # predictors only\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    X.corr(),\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1, vmax=1,\n",
    "    annot=False\n",
    ")\n",
    "plt.title(\"Correlation Matrix of Predictors\")\n",
    "plt.savefig(\"../visualizations/correlation_matrix.png\", dpi=300, bbox_inches='tight')   \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d7293",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- High correlation between G1 and G2 may indicate multicollinearity.\n",
    "- Helps guide feature selection and VIF checks later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b1cdd",
   "metadata": {},
   "source": [
    "### Association Strength for Categorical Variables\n",
    "\n",
    "We compute Pearson correlations for binary and eta-squared for multi-category features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Association Strength for Categorical Variables ----------------\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_cols = df[cat_vars]\n",
    "\n",
    "results = []\n",
    "\n",
    "for col in cat_vars:  \n",
    "    unique_vals = df[col].dropna().unique()\n",
    "\n",
    "    # Binary variable → use Pearson (point-biserial)\n",
    "    if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1}):\n",
    "        corr, pval = pearsonr(df[col], df['G3'])\n",
    "        results.append({\n",
    "            'Variable': col,\n",
    "            'Type': 'Binary',\n",
    "            'Correlation': corr,\n",
    "            'p-value': pval\n",
    "        })\n",
    "\n",
    "    # Multi-category variable → use eta-squared (from ANOVA)\n",
    "    elif len(unique_vals) > 2:\n",
    "        groups = [df.loc[df[col] == val, 'G3'].dropna() for val in unique_vals]\n",
    "        f_stat, pval = f_oneway(*groups)\n",
    "        ss_between = sum(len(g) * (g.mean() - df['G3'].mean())**2 for g in groups)\n",
    "        ss_total = sum((df['G3'] - df['G3'].mean())**2)\n",
    "        eta_sq = ss_between / ss_total if ss_total != 0 else np.nan\n",
    "        results.append({'Variable': col, 'Type': 'Multi-Category', 'Correlation': eta_sq, 'p-value': pval})\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['|Correlation|'] = results_df['Correlation'].abs()\n",
    "results_df = results_df.sort_values(by='|Correlation|', ascending=False)\n",
    "\n",
    "print(\"Strength of association between categorical variables and G3:\")\n",
    "print(results_df[['Variable', 'Type', 'Correlation', 'p-value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d80702",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "We see strong correlation between G3 and higher (pursuit of higher education), school, failures, and address (rural or urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af398cbb",
   "metadata": {},
   "source": [
    "### Association of Strength for Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Strength of Association for Numeric (Continuos) Variables ----------------\n",
    "\n",
    "#  Numeric variables: Pearson correlation with G3\n",
    "# Dictionary to store results\n",
    "numeric_results = {}\n",
    "\n",
    "for col in cont_vars:  # list of numeric predictors\n",
    "    corr, pval = pearsonr(df[col], df['G3'])\n",
    "    numeric_results[col] = {'Correlation': corr, 'p-value': pval}\n",
    "\n",
    "# Convert to DataFrame\n",
    "numeric_corr_df = pd.DataFrame(numeric_results).T  # transpose so variables are rows\n",
    "numeric_corr_df = numeric_corr_df.sort_values(by='Correlation', key=abs, ascending=False)  # sort by absolute correlation\n",
    "\n",
    "print(numeric_corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a62823",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "We see strong correlation between G3 and G1, G2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08cf20",
   "metadata": {},
   "source": [
    "### Combined Association of Strength Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ----------------- Combined Bar Plot of Numeric + Categorical Associations ------------------\n",
    "\n",
    "# Convert numeric_corr_df to match structure of results_df\n",
    "numeric_plot_df = numeric_corr_df.copy()\n",
    "numeric_plot_df['Variable'] = numeric_plot_df.index\n",
    "numeric_plot_df['Type'] = 'Numeric'\n",
    "numeric_plot_df = numeric_plot_df.reset_index(drop=True)\n",
    "\n",
    "categorical_plot_df = results_df.copy()\n",
    "categorical_plot_df = categorical_plot_df.rename(columns={'Correlation': 'Correlation', 'Variable': 'Variable'})\n",
    "\n",
    "# Combine\n",
    "combined_df = pd.concat([numeric_plot_df[['Variable', 'Type', 'Correlation']], \n",
    "                         categorical_plot_df[['Variable', 'Type', 'Correlation']]])\n",
    "\n",
    "# Sort for plotting\n",
    "combined_df['Correlation'] = combined_df['Correlation'].abs()\n",
    "combined_df = combined_df.sort_values(by='Correlation', key=abs, ascending=True)\n",
    "\n",
    "# Colors\n",
    "colors = combined_df['Type'].map({'Numeric': 'skyblue', 'Binary': 'lightgreen', 'Multi-Category': 'blue'})\n",
    "\n",
    "# Create legend patches\n",
    "legend_patches = [\n",
    "    mpatches.Patch(color='skyblue', label='Numeric'),\n",
    "    mpatches.Patch(color='lightgreen', label='Binary Categorical'),\n",
    "    mpatches.Patch(color='blue', label='Multi-Category Categorical')\n",
    "]\n",
    "\n",
    "# Plot\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.barh(\n",
    "    combined_df['Variable'], \n",
    "    combined_df['Correlation'], \n",
    "    color=colors,\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.xlabel('Correlation / Eta-squared with G3', fontsize=12)\n",
    "plt.title('Strength of Association: Numeric + Categorical Variables', fontsize=14, weight='bold')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.grid(axis='x', linestyle='--', alpha=0.4)\n",
    "plt.legend(handles=legend_patches, title='Variable Type', loc='upper right')  \n",
    "plt.tight_layout()\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.savefig(\"../visualizations/combined_association_strength.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5758755",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- Shows the absolute correlation / eta-squared values across all variables.\n",
    "- Facilitates quick identification of the most influential features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0228c62",
   "metadata": {},
   "source": [
    "### Chi Square Tests for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- Chi-square Tests for Categorical Variables -----------------\n",
    "\n",
    "alpha = 0.05  # significance threshold\n",
    "\n",
    "chi2_results = []\n",
    "\n",
    "for i in range(len(cat_vars)):\n",
    "    for j in range(i+1, len(cat_vars)):\n",
    "        var1 = cat_vars[i]\n",
    "        var2 = cat_vars[j]\n",
    "\n",
    "        # Contingency table\n",
    "        table = pd.crosstab(df[var1], df[var2])\n",
    "        chi2, p_val, dof, expected = chi2_contingency(table)\n",
    "\n",
    "        # Cramer's V effect size\n",
    "        n = table.sum().sum()\n",
    "        min_dim = min(table.shape) - 1\n",
    "        cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else np.nan\n",
    "\n",
    "        chi2_results.append({\n",
    "            \"Variable 1\": var1,\n",
    "            \"Variable 2\": var2,\n",
    "            \"Chi2\": round(chi2, 3),\n",
    "            \"p-value\": round(p_val, 5),\n",
    "            \"dof\": dof,\n",
    "            \"Cramer's V\": round(cramers_v, 3)\n",
    "        })\n",
    "\n",
    "chi2_df = pd.DataFrame(chi2_results)\n",
    "chi2_df = chi2_df.sort_values(\"p-value\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Significant Chi-square results (p < {alpha}):\")\n",
    "display(chi2_df[chi2_df[\"p-value\"] < alpha])\n",
    "print(\"Largest effect sizes (Cramer's V):\")\n",
    "display(chi2_df.sort_values(\"Cramer's V\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14c415",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Althought there are several significant tests to say there may be some correlation between variables, the highest effect size (Cramer's V) is 0.413, which is only a moderate strength of association. We shouldn't have to worry about strong associastions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10cc34",
   "metadata": {},
   "source": [
    "## Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b9021d",
   "metadata": {},
   "source": [
    "### T-tests for Binary Categorical Variables vs G3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72161879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- T-tests for Binary Categorical vs G3 ----------------\n",
    "\n",
    "alpha = 0.05  # significance threshold\n",
    "\n",
    "t_results = []\n",
    "\n",
    "target = 'G3'  # target variable\n",
    "\n",
    "for var in bin_vars:  # binary predictors\n",
    "    group0 = df[df[var] == 0][target]\n",
    "    group1 = df[df[var] == 1][target]\n",
    "\n",
    "    # Variance ratio\n",
    "    var0 = np.var(group0, ddof=1)\n",
    "    var1 = np.var(group1, ddof=1)\n",
    "    ratio = max(var0, var1) / min(var0, var1)\n",
    "\n",
    "    # Choose t-test type\n",
    "    if ratio > 1.5:\n",
    "        t_stat, p_val = ttest_ind(group0, group1, equal_var=False)\n",
    "        test_type = \"Welch's t-test\"\n",
    "    else:\n",
    "        t_stat, p_val = ttest_ind(group0, group1, equal_var=True)\n",
    "        test_type = \"Student's t-test\"\n",
    "\n",
    "    # Effect size (Cohen's d)\n",
    "    mean_diff = group1.mean() - group0.mean()\n",
    "    pooled_sd = np.sqrt((var0 + var1) / 2)\n",
    "    cohens_d = mean_diff / pooled_sd\n",
    "\n",
    "    # Append results\n",
    "    t_results.append({\n",
    "        \"Binary Variable\": var,\n",
    "        \"Target Variable\": target,\n",
    "        \"Test Type\": test_type,\n",
    "        \"t-statistic\": round(t_stat, 3),\n",
    "        \"p-value\": round(p_val, 5),\n",
    "        \"Variance Ratio\": round(ratio, 2),\n",
    "        \"Group0 Mean\": round(group0.mean(), 2),\n",
    "        \"Group1 Mean\": round(group1.mean(), 2),\n",
    "        \"Cohen's d\": round(cohens_d, 3)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "t_results_df = pd.DataFrame(t_results)\n",
    "t_results_df = t_results_df.sort_values(\"p-value\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Significant t-test results (p < {alpha}):\")\n",
    "display(t_results_df[t_results_df[\"p-value\"] < alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458f5b0",
   "metadata": {},
   "source": [
    "**Observations** \n",
    "\n",
    "Students who attend GP school, have internet access, plan for higher education, and live in urban areas tend to achieve significantly higher final grades (G3). Conversely, those receiving school support, in romantic relationships, or female students show slightly lower average grades, though these effects are smaller in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149919a9",
   "metadata": {},
   "source": [
    "### ANOVA Tests for Multi-level Categorical Variables vs G3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- ANOVA for Multi-level Categorical vs Continuous -----------------\n",
    "\n",
    "alpha = 0.05\n",
    "target = 'G3'\n",
    "anova_results = []\n",
    "\n",
    "for var in ord_vars:  # ordinal/multi-level categorical predictors\n",
    "    # Skip variables with less than 2 levels\n",
    "    if df[var].nunique() < 2:\n",
    "        continue\n",
    "    \n",
    "    # Fit ANOVA model\n",
    "    model = ols(f\"{target} ~ C({var})\", data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    f_stat = anova_table.loc[f\"C({var})\", \"F\"]\n",
    "    p_val = anova_table.loc[f\"C({var})\", \"PR(>F)\"]\n",
    "    \n",
    "    # Eta-squared: sum_sq_var / sum_sq_total\n",
    "    eta_sq = anova_table.loc[f\"C({var})\", \"sum_sq\"] / anova_table[\"sum_sq\"].sum()\n",
    "    \n",
    "    anova_results.append({\n",
    "        \"Categorical Variable\": var,\n",
    "        \"Target Variable\": target,\n",
    "        \"F-statistic\": round(f_stat, 3),\n",
    "        \"p-value\": round(p_val, 5),\n",
    "        \"Eta-squared\": round(eta_sq, 3)\n",
    "    })\n",
    "\n",
    "anova_df = pd.DataFrame(anova_results).sort_values(\"p-value\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Significant ANOVA results (p < {alpha}):\")\n",
    "display(anova_df[anova_df[\"p-value\"] < alpha])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecbb8a",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Students’ final grades (G3) vary significantly across several multi-level factors: higher parental education, more study time, and fewer past failures are strongly linked to better performance, while frequent alcohol use, more going out, and longer travel times are associated with lower grades. Overall, failures and studytime show the largest effect sizes (η² ≈ 0.19 and 0.07)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bde24b",
   "metadata": {},
   "source": [
    "## Checking Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773129a3",
   "metadata": {},
   "source": [
    "### Normal Distribution of Target Variable\n",
    "\n",
    "We being by checking if the target variable 'G3' is normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Check Distribution of 'G3' ------------------\n",
    "\n",
    "target = 'G3'\n",
    "\n",
    "# Plot distribution of target variable (raw)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[target], kde=True, color='skyblue', bins=15)\n",
    "plt.title(f\"Distribution of {target} (Raw Data)\", fontsize=14)\n",
    "plt.xlabel(target)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(\"../visualizations/g3_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Skewness and kurtosis (raw)\n",
    "skew_val_raw = df[target].skew()\n",
    "kurt_val_raw = df[target].kurtosis()\n",
    "print(f\"Raw skewness: {skew_val_raw:.2f} | Raw kurtosis: {kurt_val_raw:.2f}\")\n",
    "\n",
    "# Shapiro–Wilk test (raw)\n",
    "shapiro_stat, shapiro_p = stats.shapiro(df[target])\n",
    "print(f\"Shapiro–Wilk (raw): W = {shapiro_stat:.3f}, p = {shapiro_p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2120d5",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "G3 is clearly right-skewed, we will need to see if removing the outliers makes the distribution more normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Remove G3 Outliers and Check Distribution Again------------------\n",
    "\n",
    "# Outlier Detection (IQR method) \n",
    "Q1 = df[target].quantile(0.25)\n",
    "Q3 = df[target].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df[target] < lower_bound) | (df[target] > upper_bound)]\n",
    "print(f\"\\nNumber of potential outliers: {len(outliers)}\")\n",
    "\n",
    "# Remove outliers\n",
    "df_no_outliers = df[(df[target] >= lower_bound) & (df[target] <= upper_bound)]\n",
    "\n",
    "# Distribution and Normality (after outlier remova) \n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df_no_outliers[target], kde=True, color='orange', bins=15)\n",
    "plt.title(f\"Distribution of {target} (Outliers Removed)\", fontsize=14)\n",
    "plt.savefig(\"../visualizations/g3_distribution_no_outliers.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Skewness and kurtosis (after outlier removal)\n",
    "skew_val = df_no_outliers[target].skew()\n",
    "kurt_val = df_no_outliers[target].kurtosis()\n",
    "print(f\"After removing outliers: skewness = {skew_val:.2f}, kurtosis = {kurt_val:.2f}\")\n",
    "\n",
    "# Shapiro–Wilk (after outlier removal)\n",
    "shapiro_stat, shapiro_p = stats.shapiro(df_no_outliers[target])\n",
    "print(f\"Shapiro–Wilk (no outliers): W = {shapiro_stat:.3f}, p = {shapiro_p:.4f}\")\n",
    "\n",
    "# QQ plot for visual check\n",
    "stats.probplot(df_no_outliers[target], dist=\"norm\", plot=plt)\n",
    "plt.title(f\"QQ Plot for {target} (Outliers Removed)\")\n",
    "plt.savefig(\"../visualizations/g3_qqplot_no_outliers.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f409ae3",
   "metadata": {},
   "source": [
    "**Observations** \n",
    "\n",
    "Removing the outliers helped shape G3 to be more normally distributed.  G3 shifted from heavily left skewed to slightly right skewed.  Even though G3 with outliers removed still doesn't pass the Shapiro-Wilk significance test, the QQ plot for G3 gives enough reason to suggest we can assume a normally distributed target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b7a3dc",
   "metadata": {},
   "source": [
    "### Multicollinearity of Categorical Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08424e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Check Multicollinearity (VIF) with One-hot Encoded Multi-category Predictors ------------------\n",
    "\n",
    "# X = predictors only (after one-hot encoding)\n",
    "X = df_encoded.drop(columns=['G3'])\n",
    "X = sm.add_constant(X)  # add intercept\n",
    "\n",
    "# Compute VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Sort descending for readability\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 10 largest VIFs\n",
    "display(vif_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3234c",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The variance inflation factor (VIF) analysis indicates that multicollinearity among the predictor variables is generally low. All predictors exhibit VIF values below 5, suggesting that redundancy between variables is minimal and should not adversely affect the stability of the regression estimates. The exceptionally high VIF for the intercept (const) is expected and does not indicate multicollinearity among the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519db6b",
   "metadata": {},
   "source": [
    "### Residual Distribution of Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Fit Preliminary OLS Model to Check Residuals ------------------\n",
    "\n",
    "# Predictors (with one-hot encoding) and target\n",
    "X = df_encoded.drop(columns=['G3'])\n",
    "X = sm.add_constant(X)              # add intercept\n",
    "y = df_no_outliers['G3']            # remove outliers\n",
    "\n",
    "# Fit model\n",
    "prelim_model = sm.OLS(y, X.loc[y.index]).fit()  # align indices since using outlier-cleaned y\n",
    "\n",
    "# Residuals\n",
    "residuals = prelim_model.resid\n",
    "fitted = prelim_model.fittedvalues\n",
    "\n",
    "# Summary\n",
    "print(prelim_model.summary())\n",
    "\n",
    "# Residual Plots \n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.scatterplot(x=fitted, y=residuals, alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Fitted Values\")\n",
    "plt.savefig(\"../visualizations/residuals_vs_fitted.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# QQ Plot of residuals\n",
    "sm.qqplot(residuals, line='45', fit=True)\n",
    "plt.title(\"QQ Plot of Residuals\")\n",
    "plt.savefig(\"../visualizations/qqplot_residuals.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, kde=True, color='purple', bins=15)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.savefig(\"../visualizations/residuals_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173281f",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The residuals of the numerical features appear to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b354e26",
   "metadata": {},
   "source": [
    "### Heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008892fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  --------------- Test for Heteroscedasticity (Breusch-Pagan) ------------------\n",
    "\n",
    "# Residuals and predictors from preliminary OLS model\n",
    "lm = prelim_model  # your OLS model\n",
    "\n",
    "# Run Breusch-Pagan test\n",
    "bp_test = het_breuschpagan(lm.resid, lm.model.exog)\n",
    "bp_labels = ['LM Statistic', 'LM p-value', 'F-Statistic', 'F p-value']\n",
    "\n",
    "print(\"Breusch-Pagan Test for Heteroscedasticity:\")\n",
    "for label, value in zip(bp_labels, bp_test):\n",
    "    print(f\"{label}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05127996",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The test indicates significant heteroscedasticity, as evidenced by p-values near zero, leading to rejection of the null hypothesis. Consequently, OLS estimates may have inefficient standard errors; it is recommended to use robust standard errors and consider alternative modeling approaches that are less sensitive to heteroscedasticity, such as tree-based methods like Random Forest or Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525af55f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea92248",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We will test an OLS model with few interaction terms to see if we should include them in our final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f223f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Feature Engineering & Interaction Terms -------------------\n",
    "X_test_fe = df_encoded.drop(columns=['G3']).copy()\n",
    "y_test_fe = df_no_outliers['G3']\n",
    "X_test_fe = X_test_fe.loc[y_test_fe.index]\n",
    "\n",
    "# 1. Performance improvement (abs difference between G1 and G2)\n",
    "X_test_fe['G_perf_improve'] = abs(df_no_outliers['G2'] - df_no_outliers['G1'])\n",
    "\n",
    "# 2. Average past performance (G1 + G2)/2\n",
    "X_test_fe['G_avg'] = (df_no_outliers['G1'] + df_no_outliers['G2']) / 2\n",
    "\n",
    "# 3. Interaction term (studytime * failures)\n",
    "if 'studytime' in X_test_fe.columns and 'failures' in X_test_fe.columns:\n",
    "    X_test_fe['studytime_failures'] = X_test_fe['studytime'] * X_test_fe['failures']\n",
    "\n",
    "# 4. Interaction term (absences * studytime)\n",
    "if 'absences' in X_test_fe.columns and 'studytime' in X_test_fe.columns:\n",
    "    X_test_fe['absences_studytime'] = X_test_fe['absences'] * X_test_fe['studytime']\n",
    "\n",
    "# ------------------- Train/Test Split -------------------\n",
    "X_train_fe, X_test_fe, y_train_fe, y_test_fe = train_test_split(\n",
    "    X_test_fe, y_test_fe, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------- OLS: Baseline -------------------\n",
    "X_sm_base = sm.add_constant(X_train_fe.drop(columns=['G_perf_improve','studytime_failures','G_avg','absences_studytime']))\n",
    "ols_base = sm.OLS(y_train_fe, X_sm_base).fit()\n",
    "y_pred_base = ols_base.predict(sm.add_constant(X_test_fe.drop(columns=['G_perf_improve','studytime_failures','G_avg','absences_studytime'])))\n",
    "\n",
    "print(\"Baseline OLS Test R2:\", r2_score(y_test_fe, y_pred_base))\n",
    "print(\"Baseline OLS Test RMSE:\", mean_squared_error(y_test_fe, y_pred_base) ** 0.5)\n",
    "\n",
    "# ------------------- OLS: With Feature-Engineered Terms -------------------\n",
    "X_sm_fe = sm.add_constant(X_train_fe)\n",
    "ols_fe = sm.OLS(y_train_fe, X_sm_fe).fit()\n",
    "y_pred_fe = ols_fe.predict(sm.add_constant(X_test_fe))\n",
    "\n",
    "print(\"FE OLS Test R2:\", r2_score(y_test_fe, y_pred_fe))\n",
    "print(\"FE OLS Test RMSE:\", mean_squared_error(y_test_fe, y_pred_fe) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ae1bb",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The test set results show no improvement after adding the feature-engineered and interaction terms. R² and RMSE are largely unchanged, indicating these features do not add meaningful predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6408b",
   "metadata": {},
   "source": [
    "### Comparing Models\n",
    "\n",
    "We will use all predictors to choose the best model between OLS, Lasso, Ridge, Random Forest, and Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Data -------------------\n",
    "X = df_encoded.drop(columns=['G3'])\n",
    "y = df_no_outliers['G3']  # keep outlier removal\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# Train/test split with random seed for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize results container \n",
    "results = []\n",
    "\n",
    "# ------------------- 1. Scaled OLS -------------------\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Add constant for intercept\n",
    "X_train_scaled = sm.add_constant(X_train_scaled)\n",
    "X_test_scaled  = sm.add_constant(X_test_scaled)\n",
    "\n",
    "# Fit OLS on scaled features\n",
    "ols_model = sm.OLS(y_train, X_train_scaled).fit(cov_type='HC3') # robust SEs\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_ols = ols_model.predict(X_train_scaled)\n",
    "y_pred_test_ols  = ols_model.predict(X_test_scaled)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"OLS\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_ols) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_ols) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_ols),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_ols)\n",
    "})\n",
    "\n",
    "# ------------------- 2. Lasso -------------------\n",
    "lasso_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {'lasso__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid_lasso = GridSearchCV(lasso_pipe, param_grid, cv=5, scoring='r2')\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "best_lasso = grid_lasso.best_estimator_\n",
    "\n",
    "y_pred_train_lasso = best_lasso.predict(X_train)\n",
    "y_pred_test_lasso  = best_lasso.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Lasso\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_lasso) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_lasso) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_lasso),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_lasso)\n",
    "})\n",
    "\n",
    "# ------------------- 3. Ridge -------------------\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {'ridge__alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_ridge = GridSearchCV(ridge_pipe, param_grid, cv=5, scoring='r2')\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "\n",
    "y_pred_train_ridge = best_ridge.predict(X_train)\n",
    "y_pred_test_ridge  = best_ridge.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Ridge\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_ridge) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_ridge) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_ridge),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_ridge)\n",
    "})\n",
    "\n",
    "# ------------------- 4. Random Forest -------------------\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_rf = rf.predict(X_train)\n",
    "y_pred_test_rf  = rf.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_rf) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_rf) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_rf),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_rf)\n",
    "})\n",
    "\n",
    "# ------------------- 5. Gradient Boosting -------------------\n",
    "gb = GradientBoostingRegressor(random_state=42, n_estimators=200)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_gb = gb.predict(X_train)\n",
    "y_pred_test_gb  = gb.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Gradient Boosting\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_gb) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_gb) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_gb),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_gb)\n",
    "})\n",
    "\n",
    "# ------------------- Convert results to DataFrame -------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# ------------------- Plot comparisons -------------------\n",
    "\n",
    "# Determine the best model (lowest Test RMSE)\n",
    "best_idx = results_df['Test_RMSE'].idxmin()\n",
    "\n",
    "# Bar width and positions\n",
    "x = np.arange(len(results_df['Model']))\n",
    "width = 0.35\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "# Colors\n",
    "train_color = 'skyblue'\n",
    "test_color = 'salmon'\n",
    "highlight_edge = 'black'\n",
    "\n",
    "# RMSE Comparison\n",
    "for i in range(len(x)):\n",
    "    edge = highlight_edge if i == best_idx else None\n",
    "    axes[0].bar(x[i] - width/2, results_df['Train_RMSE'][i], width=width, color=train_color, edgecolor=edge, linewidth=2 if edge else 1, label='Train RMSE' if i==0 else \"\")\n",
    "    axes[0].bar(x[i] + width/2, results_df['Test_RMSE'][i], width=width, color=test_color, edgecolor=edge, linewidth=2 if edge else 1, label='Test RMSE' if i==0 else \"\")\n",
    "\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0].set_title(\"RMSE Comparison\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "axes[0].legend(loc='lower right')\n",
    "\n",
    "# R² Comparison\n",
    "for i in range(len(x)):\n",
    "    edge = highlight_edge if i == best_idx else None\n",
    "    axes[1].bar(x[i] - width/2, results_df['Train_R2'][i], width=width, color=train_color, edgecolor=edge, linewidth=2 if edge else 1, label='Train R²' if i==0 else \"\")\n",
    "    axes[1].bar(x[i] + width/2, results_df['Test_R2'][i], width=width, color=test_color, edgecolor=edge, linewidth=2 if edge else 1, label='Test R²' if i==0 else \"\")\n",
    "\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].set_title(\"R² Comparison\")\n",
    "axes[1].set_ylabel(\"R²\")\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.suptitle(\"Model Performance Comparison\", fontsize=16, weight='bold')\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.savefig(\"../visualizations/model_performance_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ---------------- Violin Plot ----------------\n",
    "residuals_dict = {\n",
    "    \"OLS\": y_test - y_pred_test_ols,\n",
    "    \"Lasso\": y_test - y_pred_test_lasso,\n",
    "    \"Ridge\": y_test - y_pred_test_ridge,\n",
    "    \"Random Forest\": y_test - y_pred_test_rf,\n",
    "    \"Gradient Boosting\": y_test - y_pred_test_gb\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.violinplot(\n",
    "    data=pd.DataFrame(residuals_dict),  \n",
    "    palette=\"muted\",\n",
    "    inner=\"quartile\"\n",
    ")\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residual Distribution Across Models (Violin Plot)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/residuals_violin_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6c8b0e",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "We selected the Random Forest as the best-performing model because it achieved the lowest test set RMSE. The violin plots show that its residuals are tightly clustered around zero, with a narrow, symmetric shape and the shortest range among models, indicating accurate predictions with low variance.\n",
    "\n",
    "A test R² of 0.897 indicates that approximately 89.7% of the variance in the target variable is explained by the model on unseen data. This suggests a very strong predictive performance, meaning the model captures most of the systematic patterns in the data, with only about 10% of the variance left unexplained.\n",
    "\n",
    "A test RMSE of 0.861 indicates that, on average, the model’s predictions deviate from the true values by about 0.86 units. Combined with a high R², this shows that the model predicts the target variable accurately, with relatively small errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef017c60",
   "metadata": {},
   "source": [
    "### Interpreting the Best Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Random Forest Interpretation ------------------\n",
    "\n",
    "# Identify the best model index\n",
    "best_idx = results_df['Test_RMSE'].idxmin()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "print(f\"Best model selected based on Test RMSE: {best_model_name}\")\n",
    "\n",
    "# ------------------ Predictions vs Actuals ------------------\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "plt.title(\"Random Forest: Predicted vs Actual G3\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/rf_predicted_vs_actual.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ------------------ Residuals ------------------\n",
    "residuals_rf = y_test - y_pred_rf\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_rf, kde=True, color='purple', bins=15)\n",
    "plt.title(\"Random Forest Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/rf_residuals_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ------------------ Top 10 Feature Importances (Random Forest) ------------------\n",
    "if best_model_name == \"Random Forest\":\n",
    "    rf_importances = rf.feature_importances_\n",
    "    feat_importance = pd.Series(rf_importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    top_10_features = feat_importance.head(10)\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(\n",
    "    x=top_10_features.values, \n",
    "    y=top_10_features.index, \n",
    "    hue=top_10_features.index,  \n",
    "    palette=\"viridis\",\n",
    "    legend=False                 \n",
    "    )\n",
    "    plt.title(\"Top 10 Feature Importances - Random Forest\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../visualizations/rf_top_10_feature_importances.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Top 10 important features:\")\n",
    "    display(top_10_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f677791",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "The model’s residuals are approximately normal and homoscedastic. The strongest predictors of G3 are G2, G1, absences, and age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bdff2c",
   "metadata": {},
   "source": [
    "### Comparing Models (again) `Without` 'G1' and 'G2' as Predictors\n",
    "\n",
    "We will remove 'G1' and 'G2' and choose the best model between OLS, Lasso, Ridge, Random Forest, and Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Data (remove G1 and G2) -------------------\n",
    "X = df_encoded.drop(columns=['G3', 'G1', 'G2'])\n",
    "y = df_no_outliers['G3']  # keep outlier removal\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# Train/test split with random seed for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize results container \n",
    "results = []\n",
    "\n",
    "# ------------------- 1. Scaled OLS -------------------\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Add constant for intercept\n",
    "X_train_scaled = sm.add_constant(X_train_scaled)\n",
    "X_test_scaled  = sm.add_constant(X_test_scaled)\n",
    "\n",
    "# Fit OLS on scaled features\n",
    "ols_model = sm.OLS(y_train, X_train_scaled).fit(cov_type='HC3') # robust SEs\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_ols = ols_model.predict(X_train_scaled)\n",
    "y_pred_test_ols  = ols_model.predict(X_test_scaled)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"OLS\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_ols) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_ols) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_ols),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_ols)\n",
    "})\n",
    "\n",
    "# ------------------- 2. Lasso -------------------\n",
    "lasso_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {'lasso__alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid_lasso = GridSearchCV(lasso_pipe, param_grid, cv=5, scoring='r2')\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "best_lasso = grid_lasso.best_estimator_\n",
    "\n",
    "y_pred_train_lasso = best_lasso.predict(X_train)\n",
    "y_pred_test_lasso  = best_lasso.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Lasso\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_lasso) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_lasso) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_lasso),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_lasso)\n",
    "})\n",
    "\n",
    "# ------------------- 3. Ridge -------------------\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {'ridge__alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_ridge = GridSearchCV(ridge_pipe, param_grid, cv=5, scoring='r2')\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "\n",
    "y_pred_train_ridge = best_ridge.predict(X_train)\n",
    "y_pred_test_ridge  = best_ridge.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Ridge\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_ridge) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_ridge) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_ridge),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_ridge)\n",
    "})\n",
    "\n",
    "# ------------------- 4. Random Forest -------------------\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_rf = rf.predict(X_train)\n",
    "y_pred_test_rf  = rf.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_rf) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_rf) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_rf),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_rf)\n",
    "})\n",
    "\n",
    "# ------------------- 5. Gradient Boosting -------------------\n",
    "gb = GradientBoostingRegressor(random_state=42, n_estimators=200)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_gb = gb.predict(X_train)\n",
    "y_pred_test_gb  = gb.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Gradient Boosting\",\n",
    "    \"Train_RMSE\": mean_squared_error(y_train, y_pred_train_gb) ** 0.5,\n",
    "    \"Test_RMSE\": mean_squared_error(y_test, y_pred_test_gb) ** 0.5,\n",
    "    \"Train_R2\": r2_score(y_train, y_pred_train_gb),\n",
    "    \"Test_R2\": r2_score(y_test, y_pred_test_gb)\n",
    "})\n",
    "\n",
    "# ------------------- Convert results to DataFrame -------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# ------------------- Plot comparisons -------------------\n",
    "best_idx = results_df['Test_RMSE'].idxmin()\n",
    "x = np.arange(len(results_df['Model']))\n",
    "width = 0.35\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "train_color = 'skyblue'\n",
    "test_color = 'salmon'\n",
    "highlight_edge = 'black'\n",
    "\n",
    "# RMSE\n",
    "for i in range(len(x)):\n",
    "    edge = highlight_edge if i == best_idx else None\n",
    "    axes[0].bar(x[i] - width/2, results_df['Train_RMSE'][i], width=width, color=train_color,\n",
    "                edgecolor=edge, linewidth=2 if edge else 1, label='Train RMSE' if i==0 else \"\")\n",
    "    axes[0].bar(x[i] + width/2, results_df['Test_RMSE'][i], width=width, color=test_color,\n",
    "                edgecolor=edge, linewidth=2 if edge else 1, label='Test RMSE' if i==0 else \"\")\n",
    "\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0].set_title(\"RMSE Comparison\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "axes[0].legend(loc='lower right')\n",
    "\n",
    "# R²\n",
    "for i in range(len(x)):\n",
    "    edge = highlight_edge if i == best_idx else None\n",
    "    axes[1].bar(x[i] - width/2, results_df['Train_R2'][i], width=width, color=train_color,\n",
    "                edgecolor=edge, linewidth=2 if edge else 1, label='Train R²' if i==0 else \"\")\n",
    "    axes[1].bar(x[i] + width/2, results_df['Test_R2'][i], width=width, color=test_color,\n",
    "                edgecolor=edge, linewidth=2 if edge else 1, label='Test R²' if i==0 else \"\")\n",
    "\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].set_title(\"R² Comparison\")\n",
    "axes[1].set_ylabel(\"R²\")\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.5)\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.suptitle(\"Model Performance Comparison (Without G1 & G2)\", fontsize=16, weight='bold')\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.savefig(\"../visualizations/model_performance_comparison_no_g1_g2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ---------------- Violin Plot ----------------\n",
    "residuals_dict = {\n",
    "    \"OLS\": y_test - y_pred_test_ols,\n",
    "    \"Lasso\": y_test - y_pred_test_lasso,\n",
    "    \"Ridge\": y_test - y_pred_test_ridge,\n",
    "    \"Random Forest\": y_test - y_pred_test_rf,\n",
    "    \"Gradient Boosting\": y_test - y_pred_test_gb\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.violinplot(\n",
    "    data=pd.DataFrame(residuals_dict),  # use wide-form directly\n",
    "    palette=\"muted\",\n",
    "    inner=\"quartile\"\n",
    ")\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title(\"Residual Distribution Across Models (Violin Plot)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/residuals_violin_plot_no_g1_g2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e69bc",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "We selected Ridge regression as the best-performing model because it achieved the lowest test set RMSE. The violin plots show that its residuals are tightly clustered around zero, with short tails indicating a small range of errors. Although the zero line runs through the center of the Lasso residuals as well, Ridge was preferred due to its slightly lower RMSE, reflected in the narrower distribution of residuals.\n",
    "\n",
    "As expected, the predictive power of this model with G1 and G2 removed is much lower (r2 = .39), although the purpose is to analyze how the other feature importances will change without the G1 and G2 predictors.  We will do this next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda0dd4",
   "metadata": {},
   "source": [
    "### Interpreting Best Model (again) `Without` 'G1' and 'G2' as Predictors (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Ridge Model Interpretation ------------------\n",
    "\n",
    "# Identify the best model index\n",
    "best_idx = results_df['Test_RMSE'].idxmin()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "print(f\"Best model selected based on Test RMSE: {best_model_name}\")\n",
    "\n",
    "# ------------------ Predictions vs Actuals ------------------\n",
    "# Use Ridge predictions\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(x=y_test, y=y_pred_ridge, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "plt.title(\"Ridge: Predicted vs Actual G3\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/ridge_predicted_vs_actual.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ------------------ Residuals ------------------\n",
    "residuals_ridge = y_test - y_pred_ridge\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_ridge, kde=True, color='purple', bins=15)\n",
    "plt.title(\"Ridge Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../visualizations/ridge_residuals_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ------------------ Top 10 Feature Importances (Ridge) ------------------\n",
    "if best_model_name == \"Ridge\":\n",
    "    ridge_coefs = best_ridge.named_steps['ridge'].coef_\n",
    "    feat_importance = pd.Series(ridge_coefs, index=X.columns).abs().sort_values(ascending=False)\n",
    "\n",
    "    top_10_features = feat_importance.head(10)\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(\n",
    "    x=top_10_features.values, \n",
    "    y=top_10_features.index, \n",
    "    hue=top_10_features.index,  \n",
    "    palette=\"viridis\",\n",
    "    legend=False                 \n",
    "    )\n",
    "    plt.title(\"Top 10 Feature Importances - Ridge\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Absolute Coefficient Value\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../visualizations/ridge_top_10_feature_importances.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Top 10 important features:\")\n",
    "    display(top_10_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c5697",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The model’s residuals are approximately normal and homoscedastic. The strongest predictors in this model with G1 and G2 removed are now failuers, higher (pursuit of higher education), absences, schoolsup (level of academic support), and school."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project-team-5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
